{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7434c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52947ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7b73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b5076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (0.12.21)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.6.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb) (57.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.8/site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9555e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseankoval\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4ccf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/w251/wandb/run-20220709_172521-9r6k3bmu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/seankoval/w251_hw9/runs/9r6k3bmu\" target=\"_blank\">ruby-sky-29</a></strong> to <a href=\"https://wandb.ai/seankoval/w251_hw9\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/seankoval/w251_hw9/runs/9r6k3bmu?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2e222835e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"w251_hw9\", entity=\"seankoval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3aed8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#721fdeb49f2aeea9c5eddef6eea98f3a1ce586d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce7022e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=2\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffc3d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c8c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89dbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 2\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH=500\n",
    "VAL_BATCH=500\n",
    "WORKERS=2\n",
    "# \"/home/ubuntu/data/train\"\n",
    "TRAINDIR=\"/data/train\"\n",
    "# /home/ubuntu/data/val\n",
    "VALDIR=\"/data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07268272",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0aea5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9r6k3bmu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ruby-sky-29</strong>: <a href=\"https://wandb.ai/seankoval/w251_hw9/runs/9r6k3bmu\" target=\"_blank\">https://wandb.ai/seankoval/w251_hw9/runs/9r6k3bmu</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220709_172521-9r6k3bmu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9r6k3bmu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/w251/wandb/run-20220709_172523-3sdhz0jx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/seankoval/uncategorized/runs/3sdhz0jx\" target=\"_blank\">distinctive-vortex-25</a></strong> to <a href=\"https://wandb.ai/seankoval/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/seankoval/uncategorized/runs/3sdhz0jx?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2e221f40d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08dae2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3aa13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b19dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b269af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "        \n",
    "        global_step = global_step + 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9772112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    global_step = global_step + 1\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7c6a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef5c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1b98af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c736be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5569c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "204e7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "763b28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b074a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "# set the URL (tcp port for backend)\n",
    "URL = 'tcp://54.173.7.235:1883'\n",
    "\n",
    "RANK = 1\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method=URL,rank=RANK, world_size=WORLD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a00746eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c8ebe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a80ea0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c7cece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "add51ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e9ef367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8bdff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributed.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4995121f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributed.is_mpi_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1ba548d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributed.is_nccl_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "765148ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.distributed.is_torchelastic_launched()\n",
    "#https://pytorch.org/docs/stable/distributed.html#https://oboiko.medium.com/distributed-training-with-pytorch-d1fa5f57b40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f13bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo lsof -i -P -n\n",
    "# use to debug what ports are being accessed by the python3 code for both the worker and master nodes. (It should be set by MASTER_NODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fab889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://leimao.github.io/blog/PyTorch-Distributed-Training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1906bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d9dc0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip-172-31-28-46:536:536 [0] NCCL INFO Bootstrap : Using ens5:172.31.28.46<0>\n",
      "ip-172-31-28-46:536:536 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "ip-172-31-28-46:536:536 [0] NCCL INFO P2P plugin IBext\n",
      "ip-172-31-28-46:536:536 [0] NCCL INFO NET/IB : No device found.\n",
      "ip-172-31-28-46:536:536 [0] NCCL INFO NET/IB : No device found.\n",
      "ip-172-31-28-46:536:536 [0] NCCL INFO NET/Socket : Using [0]ens5:172.31.28.46<0>\n",
      "ip-172-31-28-46:536:536 [0] NCCL INFO Using network Socket\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO Channel 00 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO Channel 01 : 0[1e0] -> 1[1e0] [receive] via NET/Socket/0\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO Channel 00 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO Channel 01 : 1[1e0] -> 0[1e0] [send] via NET/Socket/0\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO Connected all rings\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO Connected all trees\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\n",
      "ip-172-31-28-46:536:654 [0] NCCL INFO comm 0x7f2d4c008fb0 rank 1 nranks 2 cudaDev 0 busId 1e0 - Init COMPLETE\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1acba6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3045dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "350d7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67224ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomCrop(IMG_SIZE, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be7a6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "509f8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomCrop(IMG_SIZE, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cad96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b01c945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08e09c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "226333a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9996fbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 15.018 (15.018)\tData  3.539 ( 3.539)\tLoss 7.0156e+00 (7.0156e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  10/1282]\tTime  2.462 ( 2.846)\tData  1.778 ( 1.123)\tLoss 6.9121e+00 (6.9762e+00)\tAcc@1   0.20 (  0.16)\tAcc@5   1.40 (  0.67)\n",
      "Epoch: [0][  20/1282]\tTime  2.336 ( 2.365)\tData  1.672 ( 1.146)\tLoss 6.9164e+00 (6.9576e+00)\tAcc@1   0.60 (  0.22)\tAcc@5   1.40 (  0.90)\n",
      "Epoch: [0][  30/1282]\tTime  3.856 ( 2.249)\tData  3.153 ( 1.208)\tLoss 6.8459e+00 (6.9316e+00)\tAcc@1   0.00 (  0.25)\tAcc@5   1.00 (  0.99)\n",
      "Epoch: [0][  40/1282]\tTime  1.983 ( 2.187)\tData  1.322 ( 1.236)\tLoss 6.7243e+00 (6.8868e+00)\tAcc@1   1.00 (  0.38)\tAcc@5   3.00 (  1.40)\n",
      "Epoch: [0][  50/1282]\tTime  2.560 ( 2.196)\tData  1.849 ( 1.298)\tLoss 6.6617e+00 (6.8431e+00)\tAcc@1   0.60 (  0.47)\tAcc@5   1.80 (  1.69)\n",
      "Epoch: [0][  60/1282]\tTime  2.812 ( 2.132)\tData  2.072 ( 1.268)\tLoss 6.4969e+00 (6.7940e+00)\tAcc@1   0.80 (  0.55)\tAcc@5   4.40 (  1.98)\n",
      "Epoch: [0][  70/1282]\tTime  3.270 ( 2.089)\tData  2.566 ( 1.249)\tLoss 6.4607e+00 (6.7542e+00)\tAcc@1   1.40 (  0.59)\tAcc@5   3.00 (  2.23)\n",
      "Epoch: [0][  80/1282]\tTime  2.756 ( 2.058)\tData  2.011 ( 1.232)\tLoss 6.4103e+00 (6.7125e+00)\tAcc@1   1.40 (  0.68)\tAcc@5   5.80 (  2.55)\n",
      "Epoch: [0][  90/1282]\tTime  2.841 ( 2.028)\tData  2.115 ( 1.208)\tLoss 6.3055e+00 (6.6706e+00)\tAcc@1   1.60 (  0.78)\tAcc@5   5.20 (  2.85)\n",
      "Epoch: [0][ 100/1282]\tTime  2.319 ( 2.013)\tData  1.645 ( 1.197)\tLoss 6.1381e+00 (6.6302e+00)\tAcc@1   3.20 (  0.86)\tAcc@5   6.80 (  3.11)\n",
      "Epoch: [0][ 110/1282]\tTime  2.409 ( 1.995)\tData  1.733 ( 1.156)\tLoss 6.0088e+00 (6.5858e+00)\tAcc@1   2.40 (  0.96)\tAcc@5   9.20 (  3.48)\n",
      "Epoch: [0][ 120/1282]\tTime  2.658 ( 1.980)\tData  1.935 ( 1.141)\tLoss 6.0680e+00 (6.5463e+00)\tAcc@1   3.00 (  1.06)\tAcc@5   8.80 (  3.79)\n",
      "Epoch: [0][ 130/1282]\tTime  2.756 ( 1.977)\tData  2.042 ( 1.143)\tLoss 5.9319e+00 (6.5081e+00)\tAcc@1   3.60 (  1.15)\tAcc@5   9.00 (  4.09)\n",
      "Epoch: [0][ 140/1282]\tTime  3.406 ( 1.967)\tData  2.667 ( 1.137)\tLoss 6.0115e+00 (6.4725e+00)\tAcc@1   2.60 (  1.25)\tAcc@5   7.40 (  4.38)\n",
      "Epoch: [0][ 150/1282]\tTime  1.948 ( 1.957)\tData  1.272 ( 1.123)\tLoss 5.9156e+00 (6.4345e+00)\tAcc@1   4.80 (  1.35)\tAcc@5  10.80 (  4.72)\n",
      "Epoch: [0][ 160/1282]\tTime  2.533 ( 1.954)\tData  1.808 ( 1.088)\tLoss 5.8596e+00 (6.3997e+00)\tAcc@1   3.60 (  1.46)\tAcc@5   9.20 (  5.03)\n",
      "Epoch: [0][ 170/1282]\tTime  0.686 ( 1.944)\tData  0.002 ( 1.056)\tLoss 5.7545e+00 (6.3657e+00)\tAcc@1   5.20 (  1.56)\tAcc@5  11.40 (  5.32)\n",
      "Epoch: [0][ 180/1282]\tTime  0.685 ( 1.935)\tData  0.002 ( 0.998)\tLoss 5.7858e+00 (6.3339e+00)\tAcc@1   2.40 (  1.65)\tAcc@5   9.00 (  5.60)\n",
      "Epoch: [0][ 190/1282]\tTime  0.782 ( 1.929)\tData  0.096 ( 0.949)\tLoss 5.7298e+00 (6.3024e+00)\tAcc@1   3.80 (  1.76)\tAcc@5  11.40 (  5.88)\n",
      "Epoch: [0][ 200/1282]\tTime  0.777 ( 1.919)\tData  0.095 ( 0.909)\tLoss 5.7244e+00 (6.2736e+00)\tAcc@1   3.00 (  1.86)\tAcc@5  11.40 (  6.17)\n",
      "Epoch: [0][ 210/1282]\tTime  0.688 ( 1.918)\tData  0.003 ( 0.882)\tLoss 5.6103e+00 (6.2434e+00)\tAcc@1   3.40 (  1.94)\tAcc@5  13.60 (  6.47)\n",
      "Epoch: [0][ 220/1282]\tTime  0.688 ( 1.911)\tData  0.002 ( 0.843)\tLoss 5.6325e+00 (6.2169e+00)\tAcc@1   5.40 (  2.08)\tAcc@5  12.20 (  6.77)\n",
      "Epoch: [0][ 230/1282]\tTime  0.690 ( 1.914)\tData  0.003 ( 0.806)\tLoss 5.5263e+00 (6.1899e+00)\tAcc@1   5.40 (  2.19)\tAcc@5  15.20 (  7.08)\n",
      "Epoch: [0][ 240/1282]\tTime  0.785 ( 1.907)\tData  0.002 ( 0.773)\tLoss 5.5287e+00 (6.1615e+00)\tAcc@1   4.20 (  2.31)\tAcc@5  14.60 (  7.41)\n",
      "Epoch: [0][ 250/1282]\tTime  0.825 ( 1.901)\tData  0.139 ( 0.744)\tLoss 5.5135e+00 (6.1338e+00)\tAcc@1   4.60 (  2.41)\tAcc@5  14.80 (  7.71)\n",
      "Epoch: [0][ 260/1282]\tTime  1.531 ( 1.901)\tData  0.846 ( 0.729)\tLoss 5.5100e+00 (6.1071e+00)\tAcc@1   4.00 (  2.51)\tAcc@5  14.40 (  8.02)\n",
      "Epoch: [0][ 270/1282]\tTime  0.916 ( 1.897)\tData  0.229 ( 0.729)\tLoss 5.3071e+00 (6.0800e+00)\tAcc@1   5.20 (  2.65)\tAcc@5  17.40 (  8.34)\n",
      "Epoch: [0][ 280/1282]\tTime  1.341 ( 1.897)\tData  0.654 ( 0.738)\tLoss 5.3221e+00 (6.0545e+00)\tAcc@1   8.20 (  2.77)\tAcc@5  18.80 (  8.63)\n",
      "Epoch: [0][ 290/1282]\tTime  1.120 ( 1.893)\tData  0.433 ( 0.750)\tLoss 5.3244e+00 (6.0311e+00)\tAcc@1   7.40 (  2.88)\tAcc@5  18.60 (  8.92)\n",
      "Epoch: [0][ 300/1282]\tTime  0.891 ( 1.891)\tData  0.204 ( 0.762)\tLoss 5.1951e+00 (6.0057e+00)\tAcc@1   8.80 (  3.01)\tAcc@5  19.80 (  9.26)\n",
      "Epoch: [0][ 310/1282]\tTime  0.785 ( 1.890)\tData  0.094 ( 0.774)\tLoss 5.2760e+00 (5.9806e+00)\tAcc@1   5.40 (  3.12)\tAcc@5  19.00 (  9.57)\n",
      "Epoch: [0][ 320/1282]\tTime  0.796 ( 1.886)\tData  0.003 ( 0.782)\tLoss 5.2447e+00 (5.9578e+00)\tAcc@1   6.60 (  3.23)\tAcc@5  19.80 (  9.87)\n",
      "Epoch: [0][ 330/1282]\tTime  0.935 ( 1.883)\tData  0.003 ( 0.789)\tLoss 5.2516e+00 (5.9346e+00)\tAcc@1   6.20 (  3.35)\tAcc@5  19.80 ( 10.16)\n",
      "Epoch: [0][ 340/1282]\tTime  0.800 ( 1.883)\tData  0.002 ( 0.798)\tLoss 5.0790e+00 (5.9120e+00)\tAcc@1   6.20 (  3.47)\tAcc@5  18.00 ( 10.43)\n",
      "Epoch: [0][ 350/1282]\tTime  0.797 ( 1.880)\tData  0.002 ( 0.804)\tLoss 5.2463e+00 (5.8910e+00)\tAcc@1   7.60 (  3.58)\tAcc@5  19.40 ( 10.69)\n",
      "Epoch: [0][ 360/1282]\tTime  1.150 ( 1.879)\tData  0.002 ( 0.806)\tLoss 5.0837e+00 (5.8683e+00)\tAcc@1   6.60 (  3.70)\tAcc@5  19.80 ( 11.00)\n",
      "Epoch: [0][ 370/1282]\tTime  1.386 ( 1.878)\tData  0.002 ( 0.810)\tLoss 5.0758e+00 (5.8485e+00)\tAcc@1   8.80 (  3.80)\tAcc@5  20.40 ( 11.24)\n",
      "Epoch: [0][ 380/1282]\tTime  1.634 ( 1.878)\tData  0.003 ( 0.806)\tLoss 4.9697e+00 (5.8274e+00)\tAcc@1  10.20 (  3.92)\tAcc@5  25.20 ( 11.54)\n",
      "Epoch: [0][ 390/1282]\tTime  1.564 ( 1.876)\tData  0.002 ( 0.796)\tLoss 5.0201e+00 (5.8071e+00)\tAcc@1   7.60 (  4.04)\tAcc@5  21.00 ( 11.82)\n",
      "Epoch: [0][ 400/1282]\tTime  0.840 ( 1.874)\tData  0.002 ( 0.782)\tLoss 4.9805e+00 (5.7876e+00)\tAcc@1  10.00 (  4.16)\tAcc@5  23.40 ( 12.09)\n",
      "Epoch: [0][ 410/1282]\tTime  1.153 ( 1.876)\tData  0.002 ( 0.765)\tLoss 4.7827e+00 (5.7686e+00)\tAcc@1  10.40 (  4.27)\tAcc@5  26.40 ( 12.35)\n",
      "Epoch: [0][ 420/1282]\tTime  1.147 ( 1.874)\tData  0.002 ( 0.747)\tLoss 4.9036e+00 (5.7490e+00)\tAcc@1  10.80 (  4.39)\tAcc@5  25.20 ( 12.63)\n",
      "Epoch: [0][ 430/1282]\tTime  1.380 ( 1.874)\tData  0.002 ( 0.730)\tLoss 4.9420e+00 (5.7286e+00)\tAcc@1   7.00 (  4.51)\tAcc@5  23.60 ( 12.93)\n",
      "Epoch: [0][ 440/1282]\tTime  1.366 ( 1.873)\tData  0.002 ( 0.713)\tLoss 5.0224e+00 (5.7108e+00)\tAcc@1   8.40 (  4.64)\tAcc@5  20.20 ( 13.18)\n",
      "Epoch: [0][ 450/1282]\tTime  1.503 ( 1.872)\tData  0.002 ( 0.698)\tLoss 4.6210e+00 (5.6922e+00)\tAcc@1  10.20 (  4.76)\tAcc@5  27.00 ( 13.44)\n",
      "Epoch: [0][ 460/1282]\tTime  1.237 ( 1.882)\tData  0.002 ( 0.682)\tLoss 4.9508e+00 (5.6741e+00)\tAcc@1  10.20 (  4.87)\tAcc@5  25.00 ( 13.71)\n",
      "Epoch: [0][ 470/1282]\tTime  1.342 ( 1.880)\tData  0.003 ( 0.668)\tLoss 4.8723e+00 (5.6557e+00)\tAcc@1  10.80 (  4.97)\tAcc@5  24.00 ( 13.96)\n",
      "Epoch: [0][ 480/1282]\tTime  1.694 ( 1.879)\tData  0.002 ( 0.654)\tLoss 4.6892e+00 (5.6370e+00)\tAcc@1  13.40 (  5.09)\tAcc@5  30.60 ( 14.24)\n",
      "Epoch: [0][ 490/1282]\tTime  1.736 ( 1.878)\tData  0.003 ( 0.641)\tLoss 4.7031e+00 (5.6193e+00)\tAcc@1  12.20 (  5.21)\tAcc@5  26.80 ( 14.50)\n",
      "Epoch: [0][ 500/1282]\tTime  1.884 ( 1.879)\tData  0.003 ( 0.628)\tLoss 4.7845e+00 (5.6020e+00)\tAcc@1  11.00 (  5.32)\tAcc@5  26.00 ( 14.75)\n",
      "Epoch: [0][ 510/1282]\tTime  2.100 ( 1.877)\tData  0.002 ( 0.616)\tLoss 4.8828e+00 (5.5858e+00)\tAcc@1   7.80 (  5.42)\tAcc@5  25.20 ( 15.00)\n",
      "Epoch: [0][ 520/1282]\tTime  1.762 ( 1.876)\tData  0.003 ( 0.604)\tLoss 4.7198e+00 (5.5685e+00)\tAcc@1  10.40 (  5.54)\tAcc@5  28.80 ( 15.26)\n",
      "Epoch: [0][ 530/1282]\tTime  1.509 ( 1.874)\tData  0.002 ( 0.593)\tLoss 4.6644e+00 (5.5517e+00)\tAcc@1  10.60 (  5.66)\tAcc@5  29.20 ( 15.50)\n",
      "Epoch: [0][ 540/1282]\tTime  1.952 ( 1.873)\tData  0.002 ( 0.582)\tLoss 4.5295e+00 (5.5353e+00)\tAcc@1  12.60 (  5.77)\tAcc@5  28.20 ( 15.74)\n",
      "Epoch: [0][ 550/1282]\tTime  1.691 ( 1.871)\tData  0.002 ( 0.572)\tLoss 4.5491e+00 (5.5191e+00)\tAcc@1  13.80 (  5.88)\tAcc@5  31.20 ( 15.98)\n",
      "Epoch: [0][ 560/1282]\tTime  2.399 ( 1.871)\tData  0.002 ( 0.565)\tLoss 4.4909e+00 (5.5033e+00)\tAcc@1  12.40 (  5.99)\tAcc@5  32.20 ( 16.23)\n",
      "Epoch: [0][ 570/1282]\tTime  2.102 ( 1.869)\tData  0.002 ( 0.555)\tLoss 4.5754e+00 (5.4872e+00)\tAcc@1  11.60 (  6.11)\tAcc@5  31.20 ( 16.47)\n",
      "Epoch: [0][ 580/1282]\tTime  2.089 ( 1.869)\tData  0.002 ( 0.546)\tLoss 4.5557e+00 (5.4711e+00)\tAcc@1  13.80 (  6.23)\tAcc@5  29.60 ( 16.72)\n",
      "Epoch: [0][ 590/1282]\tTime  2.011 ( 1.867)\tData  0.002 ( 0.537)\tLoss 4.7865e+00 (5.4563e+00)\tAcc@1  11.60 (  6.34)\tAcc@5  28.60 ( 16.96)\n",
      "Epoch: [0][ 600/1282]\tTime  2.039 ( 1.865)\tData  0.002 ( 0.531)\tLoss 4.6623e+00 (5.4410e+00)\tAcc@1  12.60 (  6.46)\tAcc@5  28.00 ( 17.21)\n",
      "Epoch: [0][ 610/1282]\tTime  2.101 ( 1.865)\tData  0.002 ( 0.530)\tLoss 4.6067e+00 (5.4249e+00)\tAcc@1  13.00 (  6.58)\tAcc@5  30.60 ( 17.47)\n",
      "Epoch: [0][ 620/1282]\tTime  4.217 ( 1.870)\tData  0.003 ( 0.525)\tLoss 4.4246e+00 (5.4099e+00)\tAcc@1  12.20 (  6.69)\tAcc@5  33.40 ( 17.70)\n",
      "Epoch: [0][ 630/1282]\tTime  2.287 ( 1.874)\tData  0.002 ( 0.516)\tLoss 4.3314e+00 (5.3948e+00)\tAcc@1  16.00 (  6.82)\tAcc@5  36.00 ( 17.95)\n",
      "Epoch: [0][ 640/1282]\tTime  2.770 ( 1.878)\tData  0.002 ( 0.508)\tLoss 4.5087e+00 (5.3799e+00)\tAcc@1  15.20 (  6.94)\tAcc@5  32.00 ( 18.20)\n",
      "Epoch: [0][ 650/1282]\tTime  2.560 ( 1.876)\tData  0.003 ( 0.501)\tLoss 4.3150e+00 (5.3655e+00)\tAcc@1  16.00 (  7.05)\tAcc@5  34.40 ( 18.42)\n",
      "Epoch: [0][ 660/1282]\tTime  2.612 ( 1.876)\tData  0.003 ( 0.493)\tLoss 4.3015e+00 (5.3510e+00)\tAcc@1  16.80 (  7.17)\tAcc@5  36.40 ( 18.66)\n",
      "Epoch: [0][ 670/1282]\tTime  2.664 ( 1.875)\tData  0.003 ( 0.486)\tLoss 4.2931e+00 (5.3362e+00)\tAcc@1  15.20 (  7.29)\tAcc@5  34.80 ( 18.90)\n",
      "Epoch: [0][ 680/1282]\tTime  2.665 ( 1.874)\tData  0.002 ( 0.479)\tLoss 4.3573e+00 (5.3221e+00)\tAcc@1  14.80 (  7.41)\tAcc@5  34.80 ( 19.13)\n",
      "Epoch: [0][ 690/1282]\tTime  2.641 ( 1.873)\tData  0.002 ( 0.472)\tLoss 4.3781e+00 (5.3084e+00)\tAcc@1  16.40 (  7.52)\tAcc@5  33.00 ( 19.35)\n",
      "Epoch: [0][ 700/1282]\tTime  2.462 ( 1.872)\tData  0.002 ( 0.465)\tLoss 4.4071e+00 (5.2949e+00)\tAcc@1  12.60 (  7.63)\tAcc@5  31.80 ( 19.56)\n",
      "Epoch: [0][ 710/1282]\tTime  2.418 ( 1.871)\tData  0.002 ( 0.459)\tLoss 4.4433e+00 (5.2807e+00)\tAcc@1  12.80 (  7.74)\tAcc@5  32.60 ( 19.80)\n",
      "Epoch: [0][ 720/1282]\tTime  2.688 ( 1.870)\tData  0.003 ( 0.452)\tLoss 4.2129e+00 (5.2678e+00)\tAcc@1  14.80 (  7.84)\tAcc@5  38.20 ( 20.02)\n",
      "Epoch: [0][ 730/1282]\tTime  2.559 ( 1.870)\tData  0.002 ( 0.446)\tLoss 4.3394e+00 (5.2540e+00)\tAcc@1  16.00 (  7.95)\tAcc@5  36.60 ( 20.25)\n",
      "Epoch: [0][ 740/1282]\tTime  2.467 ( 1.869)\tData  0.003 ( 0.440)\tLoss 4.3231e+00 (5.2404e+00)\tAcc@1  17.00 (  8.07)\tAcc@5  37.20 ( 20.47)\n",
      "Epoch: [0][ 750/1282]\tTime  2.747 ( 1.869)\tData  0.003 ( 0.434)\tLoss 4.2633e+00 (5.2269e+00)\tAcc@1  15.00 (  8.20)\tAcc@5  36.20 ( 20.71)\n",
      "Epoch: [0][ 760/1282]\tTime  2.720 ( 1.867)\tData  0.002 ( 0.429)\tLoss 4.3570e+00 (5.2136e+00)\tAcc@1  15.00 (  8.32)\tAcc@5  34.40 ( 20.94)\n",
      "Epoch: [0][ 770/1282]\tTime  2.693 ( 1.867)\tData  0.002 ( 0.423)\tLoss 4.0008e+00 (5.1999e+00)\tAcc@1  18.40 (  8.44)\tAcc@5  41.80 ( 21.16)\n",
      "Epoch: [0][ 780/1282]\tTime  1.719 ( 1.865)\tData  0.003 ( 0.418)\tLoss 4.1316e+00 (5.1867e+00)\tAcc@1  18.00 (  8.55)\tAcc@5  39.40 ( 21.39)\n",
      "Epoch: [0][ 790/1282]\tTime  1.685 ( 1.866)\tData  0.002 ( 0.412)\tLoss 4.0497e+00 (5.1741e+00)\tAcc@1  18.60 (  8.65)\tAcc@5  41.60 ( 21.60)\n",
      "Epoch: [0][ 800/1282]\tTime  2.717 ( 1.866)\tData  0.002 ( 0.407)\tLoss 4.0709e+00 (5.1616e+00)\tAcc@1  17.40 (  8.75)\tAcc@5  39.00 ( 21.80)\n",
      "Epoch: [0][ 810/1282]\tTime  2.358 ( 1.872)\tData  0.002 ( 0.402)\tLoss 4.1022e+00 (5.1490e+00)\tAcc@1  17.60 (  8.88)\tAcc@5  39.80 ( 22.02)\n",
      "Epoch: [0][ 820/1282]\tTime  1.814 ( 1.871)\tData  0.002 ( 0.397)\tLoss 4.2075e+00 (5.1361e+00)\tAcc@1  16.60 (  9.00)\tAcc@5  37.00 ( 22.23)\n",
      "Epoch: [0][ 830/1282]\tTime  1.997 ( 1.871)\tData  0.003 ( 0.393)\tLoss 4.1750e+00 (5.1237e+00)\tAcc@1  18.00 (  9.10)\tAcc@5  43.40 ( 22.45)\n",
      "Epoch: [0][ 840/1282]\tTime  2.046 ( 1.871)\tData  0.002 ( 0.388)\tLoss 4.0689e+00 (5.1117e+00)\tAcc@1  17.20 (  9.21)\tAcc@5  39.00 ( 22.65)\n",
      "Epoch: [0][ 850/1282]\tTime  2.189 ( 1.870)\tData  0.002 ( 0.383)\tLoss 3.8917e+00 (5.0989e+00)\tAcc@1  20.20 (  9.34)\tAcc@5  42.20 ( 22.87)\n",
      "Epoch: [0][ 860/1282]\tTime  1.906 ( 1.869)\tData  0.003 ( 0.379)\tLoss 4.1673e+00 (5.0871e+00)\tAcc@1  17.00 (  9.45)\tAcc@5  38.60 ( 23.07)\n",
      "Epoch: [0][ 870/1282]\tTime  1.690 ( 1.867)\tData  0.002 ( 0.375)\tLoss 3.9555e+00 (5.0750e+00)\tAcc@1  18.80 (  9.56)\tAcc@5  42.40 ( 23.27)\n",
      "Epoch: [0][ 880/1282]\tTime  1.693 ( 1.867)\tData  0.002 ( 0.371)\tLoss 4.0558e+00 (5.0634e+00)\tAcc@1  18.20 (  9.66)\tAcc@5  40.20 ( 23.47)\n",
      "Epoch: [0][ 890/1282]\tTime  2.285 ( 1.867)\tData  0.003 ( 0.366)\tLoss 4.0404e+00 (5.0516e+00)\tAcc@1  20.40 (  9.77)\tAcc@5  39.60 ( 23.66)\n",
      "Epoch: [0][ 900/1282]\tTime  2.325 ( 1.867)\tData  0.002 ( 0.362)\tLoss 4.0098e+00 (5.0400e+00)\tAcc@1  20.80 (  9.87)\tAcc@5  44.20 ( 23.87)\n",
      "Epoch: [0][ 910/1282]\tTime  2.228 ( 1.867)\tData  0.002 ( 0.358)\tLoss 3.8956e+00 (5.0287e+00)\tAcc@1  20.40 (  9.99)\tAcc@5  44.00 ( 24.06)\n",
      "Epoch: [0][ 920/1282]\tTime  2.617 ( 1.867)\tData  0.002 ( 0.355)\tLoss 3.9376e+00 (5.0170e+00)\tAcc@1  22.40 ( 10.10)\tAcc@5  42.80 ( 24.27)\n",
      "Epoch: [0][ 930/1282]\tTime  2.904 ( 1.868)\tData  0.002 ( 0.351)\tLoss 3.9584e+00 (5.0056e+00)\tAcc@1  21.00 ( 10.22)\tAcc@5  42.40 ( 24.47)\n",
      "Epoch: [0][ 940/1282]\tTime  2.716 ( 1.867)\tData  0.003 ( 0.347)\tLoss 4.0493e+00 (4.9947e+00)\tAcc@1  22.20 ( 10.33)\tAcc@5  42.40 ( 24.66)\n",
      "Epoch: [0][ 950/1282]\tTime  3.494 ( 1.868)\tData  0.002 ( 0.343)\tLoss 4.0283e+00 (4.9835e+00)\tAcc@1  20.20 ( 10.45)\tAcc@5  41.40 ( 24.86)\n",
      "Epoch: [0][ 960/1282]\tTime  2.762 ( 1.867)\tData  0.002 ( 0.340)\tLoss 3.9299e+00 (4.9723e+00)\tAcc@1  22.80 ( 10.57)\tAcc@5  42.60 ( 25.07)\n",
      "Epoch: [0][ 970/1282]\tTime  2.643 ( 1.866)\tData  0.002 ( 0.336)\tLoss 4.0085e+00 (4.9610e+00)\tAcc@1  18.80 ( 10.68)\tAcc@5  39.00 ( 25.27)\n",
      "Epoch: [0][ 980/1282]\tTime  2.727 ( 1.866)\tData  0.003 ( 0.333)\tLoss 3.7764e+00 (4.9499e+00)\tAcc@1  25.40 ( 10.79)\tAcc@5  45.80 ( 25.46)\n",
      "Epoch: [0][ 990/1282]\tTime  3.178 ( 1.866)\tData  0.002 ( 0.330)\tLoss 3.8768e+00 (4.9390e+00)\tAcc@1  17.40 ( 10.90)\tAcc@5  40.60 ( 25.65)\n",
      "Epoch: [0][1000/1282]\tTime  3.388 ( 1.866)\tData  0.003 ( 0.326)\tLoss 3.9375e+00 (4.9287e+00)\tAcc@1  20.20 ( 10.99)\tAcc@5  44.80 ( 25.83)\n",
      "Epoch: [0][1010/1282]\tTime  2.767 ( 1.865)\tData  0.003 ( 0.323)\tLoss 3.7737e+00 (4.9182e+00)\tAcc@1  20.80 ( 11.08)\tAcc@5  46.60 ( 26.02)\n",
      "Epoch: [0][1020/1282]\tTime  2.964 ( 1.865)\tData  0.002 ( 0.320)\tLoss 3.8231e+00 (4.9081e+00)\tAcc@1  21.40 ( 11.18)\tAcc@5  47.80 ( 26.20)\n",
      "Epoch: [0][1030/1282]\tTime  2.845 ( 1.866)\tData  0.002 ( 0.317)\tLoss 3.7887e+00 (4.8972e+00)\tAcc@1  24.20 ( 11.30)\tAcc@5  48.40 ( 26.39)\n",
      "Epoch: [0][1040/1282]\tTime  3.024 ( 1.866)\tData  0.002 ( 0.314)\tLoss 3.6959e+00 (4.8864e+00)\tAcc@1  21.00 ( 11.42)\tAcc@5  46.80 ( 26.59)\n",
      "Epoch: [0][1050/1282]\tTime  2.892 ( 1.865)\tData  0.003 ( 0.311)\tLoss 3.6088e+00 (4.8757e+00)\tAcc@1  24.00 ( 11.53)\tAcc@5  50.80 ( 26.78)\n",
      "Epoch: [0][1060/1282]\tTime  2.850 ( 1.865)\tData  0.002 ( 0.308)\tLoss 3.7585e+00 (4.8650e+00)\tAcc@1  22.00 ( 11.64)\tAcc@5  46.20 ( 26.97)\n",
      "Epoch: [0][1070/1282]\tTime  3.151 ( 1.865)\tData  0.002 ( 0.305)\tLoss 3.7625e+00 (4.8554e+00)\tAcc@1  23.20 ( 11.73)\tAcc@5  44.60 ( 27.14)\n",
      "Epoch: [0][1080/1282]\tTime  3.122 ( 1.865)\tData  0.002 ( 0.302)\tLoss 3.6877e+00 (4.8451e+00)\tAcc@1  22.60 ( 11.85)\tAcc@5  51.40 ( 27.33)\n",
      "Epoch: [0][1090/1282]\tTime  2.814 ( 1.864)\tData  0.002 ( 0.300)\tLoss 3.7435e+00 (4.8350e+00)\tAcc@1  23.80 ( 11.95)\tAcc@5  46.60 ( 27.51)\n",
      "Epoch: [0][1100/1282]\tTime  2.562 ( 1.864)\tData  0.002 ( 0.297)\tLoss 3.7662e+00 (4.8247e+00)\tAcc@1  23.80 ( 12.06)\tAcc@5  48.60 ( 27.70)\n",
      "Epoch: [0][1110/1282]\tTime  2.674 ( 1.864)\tData  0.002 ( 0.294)\tLoss 3.6854e+00 (4.8154e+00)\tAcc@1  22.60 ( 12.15)\tAcc@5  48.00 ( 27.86)\n",
      "Epoch: [0][1120/1282]\tTime  2.809 ( 1.863)\tData  0.002 ( 0.292)\tLoss 3.7783e+00 (4.8054e+00)\tAcc@1  19.60 ( 12.26)\tAcc@5  43.80 ( 28.04)\n",
      "Epoch: [0][1130/1282]\tTime  2.023 ( 1.863)\tData  0.002 ( 0.292)\tLoss 3.7680e+00 (4.7961e+00)\tAcc@1  23.20 ( 12.36)\tAcc@5  45.20 ( 28.21)\n",
      "Epoch: [0][1140/1282]\tTime  2.977 ( 1.863)\tData  0.002 ( 0.291)\tLoss 3.5378e+00 (4.7863e+00)\tAcc@1  26.60 ( 12.46)\tAcc@5  53.40 ( 28.39)\n",
      "Epoch: [0][1150/1282]\tTime  3.261 ( 1.863)\tData  0.002 ( 0.288)\tLoss 3.6970e+00 (4.7764e+00)\tAcc@1  25.40 ( 12.57)\tAcc@5  49.40 ( 28.56)\n",
      "Epoch: [0][1160/1282]\tTime  3.147 ( 1.864)\tData  0.002 ( 0.286)\tLoss 3.7706e+00 (4.7670e+00)\tAcc@1  21.60 ( 12.66)\tAcc@5  48.40 ( 28.73)\n",
      "Epoch: [0][1170/1282]\tTime  2.754 ( 1.864)\tData  0.002 ( 0.283)\tLoss 3.8217e+00 (4.7578e+00)\tAcc@1  22.00 ( 12.75)\tAcc@5  47.40 ( 28.89)\n",
      "Epoch: [0][1180/1282]\tTime  1.947 ( 1.863)\tData  0.002 ( 0.281)\tLoss 3.6768e+00 (4.7480e+00)\tAcc@1  23.20 ( 12.86)\tAcc@5  44.60 ( 29.07)\n",
      "Epoch: [0][1190/1282]\tTime  1.417 ( 1.863)\tData  0.002 ( 0.279)\tLoss 3.6749e+00 (4.7385e+00)\tAcc@1  22.80 ( 12.96)\tAcc@5  52.20 ( 29.24)\n",
      "Epoch: [0][1200/1282]\tTime  1.133 ( 1.863)\tData  0.002 ( 0.276)\tLoss 3.5961e+00 (4.7288e+00)\tAcc@1  26.00 ( 13.07)\tAcc@5  49.40 ( 29.42)\n",
      "Epoch: [0][1210/1282]\tTime  0.814 ( 1.864)\tData  0.002 ( 0.274)\tLoss 3.7366e+00 (4.7189e+00)\tAcc@1  23.00 ( 13.18)\tAcc@5  48.20 ( 29.60)\n",
      "Epoch: [0][1220/1282]\tTime  0.811 ( 1.864)\tData  0.002 ( 0.272)\tLoss 3.5619e+00 (4.7096e+00)\tAcc@1  25.80 ( 13.28)\tAcc@5  49.20 ( 29.77)\n",
      "Epoch: [0][1230/1282]\tTime  1.066 ( 1.864)\tData  0.002 ( 0.270)\tLoss 3.6260e+00 (4.7003e+00)\tAcc@1  26.00 ( 13.38)\tAcc@5  49.00 ( 29.94)\n",
      "Epoch: [0][1240/1282]\tTime  0.822 ( 1.864)\tData  0.003 ( 0.268)\tLoss 3.5574e+00 (4.6911e+00)\tAcc@1  26.40 ( 13.48)\tAcc@5  50.40 ( 30.10)\n",
      "Epoch: [0][1250/1282]\tTime  0.729 ( 1.863)\tData  0.002 ( 0.265)\tLoss 3.4277e+00 (4.6821e+00)\tAcc@1  27.80 ( 13.57)\tAcc@5  54.40 ( 30.26)\n",
      "Epoch: [0][1260/1282]\tTime  0.728 ( 1.863)\tData  0.002 ( 0.263)\tLoss 3.7143e+00 (4.6734e+00)\tAcc@1  23.60 ( 13.67)\tAcc@5  47.20 ( 30.42)\n",
      "Epoch: [0][1270/1282]\tTime  0.719 ( 1.863)\tData  0.002 ( 0.261)\tLoss 3.5042e+00 (4.6645e+00)\tAcc@1  27.00 ( 13.77)\tAcc@5  50.40 ( 30.57)\n",
      "Epoch: [0][1280/1282]\tTime  0.718 ( 1.864)\tData  0.002 ( 0.259)\tLoss 3.3196e+00 (4.6552e+00)\tAcc@1  31.20 ( 13.89)\tAcc@5  55.20 ( 30.75)\n",
      "Test: [  0/100]\tTime  6.870 ( 6.870)\tLoss 3.7305e+00 (3.7305e+00)\tAcc@1  21.40 ( 21.40)\tAcc@5  50.60 ( 50.60)\n",
      "Test: [ 10/100]\tTime  3.200 ( 2.090)\tLoss 4.3668e+00 (4.2856e+00)\tAcc@1  23.80 ( 20.55)\tAcc@5  39.40 ( 40.95)\n",
      "Test: [ 20/100]\tTime  3.094 ( 1.961)\tLoss 4.7059e+00 (4.2893e+00)\tAcc@1   7.20 ( 18.90)\tAcc@5  30.60 ( 39.76)\n",
      "Test: [ 30/100]\tTime  3.145 ( 1.915)\tLoss 4.2410e+00 (4.3171e+00)\tAcc@1  15.60 ( 17.48)\tAcc@5  42.20 ( 39.14)\n",
      "Test: [ 40/100]\tTime  2.816 ( 1.897)\tLoss 3.4784e+00 (4.3361e+00)\tAcc@1  29.00 ( 18.02)\tAcc@5  52.80 ( 39.09)\n",
      "Test: [ 50/100]\tTime  2.955 ( 1.879)\tLoss 5.4020e+00 (4.3604e+00)\tAcc@1   5.60 ( 17.33)\tAcc@5  18.20 ( 38.15)\n",
      "Test: [ 60/100]\tTime  2.921 ( 1.868)\tLoss 4.3693e+00 (4.3430e+00)\tAcc@1  18.00 ( 17.57)\tAcc@5  35.00 ( 38.14)\n",
      "Test: [ 70/100]\tTime  3.015 ( 1.851)\tLoss 4.1603e+00 (4.3418e+00)\tAcc@1  15.00 ( 17.39)\tAcc@5  38.20 ( 38.08)\n",
      "Test: [ 80/100]\tTime  3.372 ( 1.844)\tLoss 4.1730e+00 (4.3406e+00)\tAcc@1  21.60 ( 17.46)\tAcc@5  41.40 ( 37.98)\n",
      "Test: [ 90/100]\tTime  3.001 ( 1.832)\tLoss 4.3372e+00 (4.3415e+00)\tAcc@1  18.20 ( 17.28)\tAcc@5  36.40 ( 37.73)\n",
      " * Acc@1 17.414 Acc@5 37.720\n",
      "lr: 0.05\n",
      "Epoch: [1][   0/1282]\tTime 11.922 (11.922)\tData  3.954 ( 3.954)\tLoss 3.6243e+00 (3.6243e+00)\tAcc@1  25.80 ( 25.80)\tAcc@5  51.00 ( 51.00)\n",
      "Epoch: [1][  10/1282]\tTime  2.759 ( 2.720)\tData  0.003 ( 0.362)\tLoss 3.5341e+00 (3.5076e+00)\tAcc@1  27.20 ( 26.44)\tAcc@5  51.00 ( 51.22)\n",
      "Epoch: [1][  20/1282]\tTime  2.707 ( 2.270)\tData  0.002 ( 0.191)\tLoss 3.3301e+00 (3.4484e+00)\tAcc@1  29.20 ( 27.64)\tAcc@5  53.80 ( 52.25)\n",
      "Epoch: [1][  30/1282]\tTime  2.818 ( 2.130)\tData  0.002 ( 0.130)\tLoss 3.3179e+00 (3.4038e+00)\tAcc@1  28.40 ( 28.64)\tAcc@5  54.80 ( 53.50)\n",
      "Epoch: [1][  40/1282]\tTime  2.843 ( 2.061)\tData  0.002 ( 0.099)\tLoss 3.2885e+00 (3.3827e+00)\tAcc@1  28.40 ( 28.94)\tAcc@5  55.80 ( 53.95)\n",
      "Epoch: [1][  50/1282]\tTime  2.355 ( 2.006)\tData  0.002 ( 0.080)\tLoss 3.4369e+00 (3.3669e+00)\tAcc@1  27.80 ( 29.24)\tAcc@5  53.20 ( 54.15)\n",
      "Epoch: [1][  60/1282]\tTime  1.841 ( 1.970)\tData  0.003 ( 0.067)\tLoss 3.3218e+00 (3.3598e+00)\tAcc@1  29.40 ( 29.40)\tAcc@5  55.40 ( 54.38)\n",
      "Epoch: [1][  70/1282]\tTime  1.361 ( 1.940)\tData  0.002 ( 0.058)\tLoss 3.2770e+00 (3.3473e+00)\tAcc@1  28.80 ( 29.59)\tAcc@5  55.40 ( 54.65)\n",
      "Epoch: [1][  80/1282]\tTime  0.811 ( 1.923)\tData  0.002 ( 0.051)\tLoss 3.2564e+00 (3.3446e+00)\tAcc@1  32.00 ( 29.61)\tAcc@5  59.20 ( 54.72)\n",
      "Epoch: [1][  90/1282]\tTime  0.878 ( 1.911)\tData  0.002 ( 0.046)\tLoss 3.2358e+00 (3.3392e+00)\tAcc@1  28.40 ( 29.58)\tAcc@5  56.40 ( 54.67)\n",
      "Epoch: [1][ 100/1282]\tTime  0.814 ( 1.897)\tData  0.002 ( 0.042)\tLoss 3.0425e+00 (3.3240e+00)\tAcc@1  34.00 ( 29.82)\tAcc@5  62.40 ( 54.92)\n",
      "Epoch: [1][ 110/1282]\tTime  0.723 ( 1.888)\tData  0.002 ( 0.038)\tLoss 3.0643e+00 (3.3165e+00)\tAcc@1  31.40 ( 29.86)\tAcc@5  59.60 ( 55.08)\n",
      "Epoch: [1][ 120/1282]\tTime  0.812 ( 1.875)\tData  0.002 ( 0.035)\tLoss 3.1807e+00 (3.3097e+00)\tAcc@1  30.80 ( 29.99)\tAcc@5  57.00 ( 55.23)\n",
      "Epoch: [1][ 130/1282]\tTime  1.095 ( 1.870)\tData  0.002 ( 0.033)\tLoss 3.0646e+00 (3.3074e+00)\tAcc@1  33.40 ( 29.97)\tAcc@5  62.80 ( 55.30)\n",
      "Epoch: [1][ 140/1282]\tTime  0.813 ( 1.863)\tData  0.002 ( 0.031)\tLoss 3.2416e+00 (3.3043e+00)\tAcc@1  32.80 ( 30.04)\tAcc@5  54.60 ( 55.33)\n",
      "Epoch: [1][ 150/1282]\tTime  0.724 ( 1.862)\tData  0.002 ( 0.029)\tLoss 3.3220e+00 (3.2953e+00)\tAcc@1  29.20 ( 30.17)\tAcc@5  57.00 ( 55.48)\n",
      "Epoch: [1][ 160/1282]\tTime  0.725 ( 1.863)\tData  0.002 ( 0.027)\tLoss 3.2408e+00 (3.2914e+00)\tAcc@1  28.80 ( 30.24)\tAcc@5  58.80 ( 55.60)\n",
      "Epoch: [1][ 170/1282]\tTime  0.763 ( 1.859)\tData  0.002 ( 0.026)\tLoss 3.0878e+00 (3.2876e+00)\tAcc@1  33.00 ( 30.28)\tAcc@5  59.40 ( 55.63)\n",
      "Epoch: [1][ 180/1282]\tTime  0.725 ( 1.855)\tData  0.003 ( 0.024)\tLoss 3.2854e+00 (3.2837e+00)\tAcc@1  28.40 ( 30.33)\tAcc@5  56.80 ( 55.73)\n",
      "Epoch: [1][ 190/1282]\tTime  1.049 ( 1.860)\tData  0.002 ( 0.023)\tLoss 3.2608e+00 (3.2793e+00)\tAcc@1  30.60 ( 30.39)\tAcc@5  55.40 ( 55.78)\n",
      "Epoch: [1][ 200/1282]\tTime  1.019 ( 1.861)\tData  0.002 ( 0.022)\tLoss 3.2944e+00 (3.2775e+00)\tAcc@1  29.80 ( 30.43)\tAcc@5  57.20 ( 55.83)\n",
      "Epoch: [1][ 210/1282]\tTime  1.253 ( 1.860)\tData  0.002 ( 0.021)\tLoss 3.1331e+00 (3.2736e+00)\tAcc@1  34.00 ( 30.55)\tAcc@5  59.20 ( 55.94)\n",
      "Epoch: [1][ 220/1282]\tTime  1.255 ( 1.856)\tData  0.002 ( 0.020)\tLoss 3.1069e+00 (3.2727e+00)\tAcc@1  36.20 ( 30.55)\tAcc@5  59.20 ( 55.92)\n",
      "Epoch: [1][ 230/1282]\tTime  0.939 ( 1.853)\tData  0.002 ( 0.020)\tLoss 3.1114e+00 (3.2696e+00)\tAcc@1  35.40 ( 30.64)\tAcc@5  59.80 ( 55.97)\n",
      "Epoch: [1][ 240/1282]\tTime  1.228 ( 1.852)\tData  0.002 ( 0.019)\tLoss 3.1493e+00 (3.2650e+00)\tAcc@1  30.40 ( 30.68)\tAcc@5  56.40 ( 56.05)\n",
      "Epoch: [1][ 250/1282]\tTime  1.189 ( 1.851)\tData  0.002 ( 0.018)\tLoss 3.3723e+00 (3.2618e+00)\tAcc@1  26.60 ( 30.72)\tAcc@5  54.20 ( 56.11)\n",
      "Epoch: [1][ 260/1282]\tTime  0.914 ( 1.850)\tData  0.002 ( 0.018)\tLoss 3.3981e+00 (3.2577e+00)\tAcc@1  29.20 ( 30.78)\tAcc@5  54.80 ( 56.18)\n",
      "Epoch: [1][ 270/1282]\tTime  0.812 ( 1.848)\tData  0.002 ( 0.017)\tLoss 3.1987e+00 (3.2548e+00)\tAcc@1  29.60 ( 30.82)\tAcc@5  54.00 ( 56.23)\n",
      "Epoch: [1][ 280/1282]\tTime  0.818 ( 1.846)\tData  0.002 ( 0.017)\tLoss 3.0868e+00 (3.2510e+00)\tAcc@1  35.20 ( 30.87)\tAcc@5  60.20 ( 56.29)\n",
      "Epoch: [1][ 290/1282]\tTime  1.882 ( 1.848)\tData  0.002 ( 0.016)\tLoss 3.0073e+00 (3.2469e+00)\tAcc@1  32.60 ( 30.92)\tAcc@5  58.20 ( 56.35)\n",
      "Epoch: [1][ 300/1282]\tTime  1.287 ( 1.846)\tData  0.002 ( 0.016)\tLoss 3.1225e+00 (3.2422e+00)\tAcc@1  33.80 ( 31.03)\tAcc@5  58.60 ( 56.44)\n",
      "Epoch: [1][ 310/1282]\tTime  1.579 ( 1.847)\tData  0.002 ( 0.015)\tLoss 3.1176e+00 (3.2383e+00)\tAcc@1  34.00 ( 31.08)\tAcc@5  59.20 ( 56.54)\n",
      "Epoch: [1][ 320/1282]\tTime  2.020 ( 1.847)\tData  0.002 ( 0.015)\tLoss 3.1293e+00 (3.2349e+00)\tAcc@1  32.40 ( 31.12)\tAcc@5  58.60 ( 56.60)\n",
      "Epoch: [1][ 330/1282]\tTime  1.627 ( 1.846)\tData  0.002 ( 0.014)\tLoss 3.0976e+00 (3.2326e+00)\tAcc@1  32.60 ( 31.14)\tAcc@5  60.60 ( 56.66)\n",
      "Epoch: [1][ 340/1282]\tTime  1.594 ( 1.845)\tData  0.002 ( 0.014)\tLoss 3.1151e+00 (3.2293e+00)\tAcc@1  33.80 ( 31.19)\tAcc@5  60.40 ( 56.71)\n",
      "Epoch: [1][ 350/1282]\tTime  1.988 ( 1.845)\tData  0.002 ( 0.014)\tLoss 3.2260e+00 (3.2257e+00)\tAcc@1  31.80 ( 31.25)\tAcc@5  56.40 ( 56.76)\n",
      "Epoch: [1][ 360/1282]\tTime  1.661 ( 1.844)\tData  0.002 ( 0.013)\tLoss 3.1277e+00 (3.2220e+00)\tAcc@1  32.40 ( 31.29)\tAcc@5  57.40 ( 56.82)\n",
      "Epoch: [1][ 370/1282]\tTime  1.861 ( 1.843)\tData  0.002 ( 0.013)\tLoss 3.1064e+00 (3.2197e+00)\tAcc@1  33.40 ( 31.33)\tAcc@5  59.80 ( 56.86)\n",
      "Epoch: [1][ 380/1282]\tTime  2.165 ( 1.842)\tData  0.003 ( 0.013)\tLoss 2.8737e+00 (3.2164e+00)\tAcc@1  35.80 ( 31.38)\tAcc@5  61.40 ( 56.93)\n",
      "Epoch: [1][ 390/1282]\tTime  2.180 ( 1.842)\tData  0.003 ( 0.013)\tLoss 3.0508e+00 (3.2129e+00)\tAcc@1  33.40 ( 31.43)\tAcc@5  59.60 ( 57.01)\n",
      "Epoch: [1][ 400/1282]\tTime  1.589 ( 1.841)\tData  0.002 ( 0.012)\tLoss 2.9567e+00 (3.2101e+00)\tAcc@1  35.60 ( 31.49)\tAcc@5  58.60 ( 57.05)\n",
      "Epoch: [1][ 410/1282]\tTime  1.930 ( 1.841)\tData  0.002 ( 0.012)\tLoss 2.8917e+00 (3.2080e+00)\tAcc@1  35.40 ( 31.54)\tAcc@5  61.00 ( 57.08)\n",
      "Epoch: [1][ 420/1282]\tTime  2.038 ( 1.841)\tData  0.002 ( 0.012)\tLoss 2.9714e+00 (3.2046e+00)\tAcc@1  34.20 ( 31.60)\tAcc@5  62.20 ( 57.14)\n",
      "Epoch: [1][ 430/1282]\tTime  2.114 ( 1.840)\tData  0.002 ( 0.012)\tLoss 3.0026e+00 (3.2018e+00)\tAcc@1  33.20 ( 31.65)\tAcc@5  60.20 ( 57.19)\n",
      "Epoch: [1][ 440/1282]\tTime  1.903 ( 1.839)\tData  0.003 ( 0.011)\tLoss 2.9975e+00 (3.1988e+00)\tAcc@1  34.00 ( 31.70)\tAcc@5  62.00 ( 57.25)\n",
      "Epoch: [1][ 450/1282]\tTime  2.193 ( 1.838)\tData  0.002 ( 0.011)\tLoss 2.8644e+00 (3.1970e+00)\tAcc@1  34.00 ( 31.74)\tAcc@5  61.60 ( 57.29)\n",
      "Epoch: [1][ 460/1282]\tTime  1.968 ( 1.837)\tData  0.002 ( 0.011)\tLoss 3.0927e+00 (3.1942e+00)\tAcc@1  32.80 ( 31.78)\tAcc@5  58.00 ( 57.34)\n",
      "Epoch: [1][ 470/1282]\tTime  2.116 ( 1.837)\tData  0.002 ( 0.011)\tLoss 3.1808e+00 (3.1911e+00)\tAcc@1  28.40 ( 31.80)\tAcc@5  56.00 ( 57.40)\n",
      "Epoch: [1][ 480/1282]\tTime  2.385 ( 1.837)\tData  0.002 ( 0.011)\tLoss 2.9825e+00 (3.1876e+00)\tAcc@1  36.60 ( 31.86)\tAcc@5  62.60 ( 57.46)\n",
      "Epoch: [1][ 490/1282]\tTime  2.214 ( 1.836)\tData  0.003 ( 0.011)\tLoss 3.0852e+00 (3.1856e+00)\tAcc@1  35.20 ( 31.90)\tAcc@5  59.00 ( 57.52)\n",
      "Epoch: [1][ 500/1282]\tTime  2.430 ( 1.836)\tData  0.003 ( 0.010)\tLoss 3.0913e+00 (3.1830e+00)\tAcc@1  32.60 ( 31.95)\tAcc@5  59.20 ( 57.57)\n",
      "Epoch: [1][ 510/1282]\tTime  2.634 ( 1.836)\tData  0.003 ( 0.010)\tLoss 3.2304e+00 (3.1810e+00)\tAcc@1  29.60 ( 31.99)\tAcc@5  55.80 ( 57.61)\n",
      "Epoch: [1][ 520/1282]\tTime  2.524 ( 1.836)\tData  0.002 ( 0.010)\tLoss 3.0689e+00 (3.1776e+00)\tAcc@1  32.00 ( 32.04)\tAcc@5  60.20 ( 57.69)\n",
      "Epoch: [1][ 530/1282]\tTime  2.499 ( 1.835)\tData  0.002 ( 0.010)\tLoss 3.1537e+00 (3.1753e+00)\tAcc@1  32.20 ( 32.08)\tAcc@5  57.40 ( 57.72)\n",
      "Epoch: [1][ 540/1282]\tTime  2.738 ( 1.835)\tData  0.002 ( 0.010)\tLoss 2.8552e+00 (3.1734e+00)\tAcc@1  36.40 ( 32.11)\tAcc@5  62.80 ( 57.75)\n",
      "Epoch: [1][ 550/1282]\tTime  1.937 ( 1.834)\tData  0.002 ( 0.014)\tLoss 2.9337e+00 (3.1709e+00)\tAcc@1  38.40 ( 32.15)\tAcc@5  62.40 ( 57.80)\n",
      "Epoch: [1][ 560/1282]\tTime  2.202 ( 1.835)\tData  0.002 ( 0.024)\tLoss 3.0062e+00 (3.1683e+00)\tAcc@1  33.40 ( 32.19)\tAcc@5  60.20 ( 57.85)\n",
      "Epoch: [1][ 570/1282]\tTime  3.504 ( 1.838)\tData  0.002 ( 0.026)\tLoss 2.9733e+00 (3.1657e+00)\tAcc@1  36.40 ( 32.23)\tAcc@5  61.60 ( 57.88)\n",
      "Epoch: [1][ 580/1282]\tTime  2.864 ( 1.838)\tData  0.002 ( 0.025)\tLoss 3.1438e+00 (3.1633e+00)\tAcc@1  34.20 ( 32.26)\tAcc@5  60.40 ( 57.92)\n",
      "Epoch: [1][ 590/1282]\tTime  2.710 ( 1.838)\tData  0.002 ( 0.025)\tLoss 3.2380e+00 (3.1610e+00)\tAcc@1  31.80 ( 32.30)\tAcc@5  53.00 ( 57.96)\n",
      "Epoch: [1][ 600/1282]\tTime  2.890 ( 1.837)\tData  0.002 ( 0.025)\tLoss 3.2414e+00 (3.1591e+00)\tAcc@1  31.00 ( 32.33)\tAcc@5  52.40 ( 57.99)\n",
      "Epoch: [1][ 610/1282]\tTime  2.865 ( 1.837)\tData  0.002 ( 0.024)\tLoss 3.0447e+00 (3.1557e+00)\tAcc@1  34.40 ( 32.39)\tAcc@5  59.80 ( 58.06)\n",
      "Epoch: [1][ 620/1282]\tTime  2.939 ( 1.836)\tData  0.002 ( 0.024)\tLoss 2.9201e+00 (3.1535e+00)\tAcc@1  36.80 ( 32.42)\tAcc@5  63.40 ( 58.09)\n",
      "Epoch: [1][ 630/1282]\tTime  2.823 ( 1.836)\tData  0.002 ( 0.023)\tLoss 2.9882e+00 (3.1513e+00)\tAcc@1  35.40 ( 32.46)\tAcc@5  60.00 ( 58.13)\n",
      "Epoch: [1][ 640/1282]\tTime  2.964 ( 1.836)\tData  0.002 ( 0.023)\tLoss 3.1512e+00 (3.1493e+00)\tAcc@1  32.40 ( 32.50)\tAcc@5  55.40 ( 58.16)\n",
      "Epoch: [1][ 650/1282]\tTime  2.745 ( 1.835)\tData  0.002 ( 0.023)\tLoss 2.9397e+00 (3.1472e+00)\tAcc@1  34.80 ( 32.54)\tAcc@5  62.40 ( 58.20)\n",
      "Epoch: [1][ 660/1282]\tTime  2.681 ( 1.835)\tData  0.003 ( 0.023)\tLoss 3.0004e+00 (3.1450e+00)\tAcc@1  36.40 ( 32.58)\tAcc@5  61.40 ( 58.25)\n",
      "Epoch: [1][ 670/1282]\tTime  3.161 ( 1.835)\tData  0.003 ( 0.022)\tLoss 2.9544e+00 (3.1425e+00)\tAcc@1  36.00 ( 32.62)\tAcc@5  59.80 ( 58.29)\n",
      "Epoch: [1][ 680/1282]\tTime  2.893 ( 1.835)\tData  0.003 ( 0.022)\tLoss 2.9969e+00 (3.1402e+00)\tAcc@1  37.20 ( 32.67)\tAcc@5  62.40 ( 58.33)\n",
      "Epoch: [1][ 690/1282]\tTime  2.692 ( 1.835)\tData  0.095 ( 0.024)\tLoss 2.9929e+00 (3.1383e+00)\tAcc@1  35.20 ( 32.69)\tAcc@5  59.80 ( 58.37)\n",
      "Epoch: [1][ 700/1282]\tTime  2.735 ( 1.835)\tData  0.003 ( 0.025)\tLoss 3.0250e+00 (3.1361e+00)\tAcc@1  33.00 ( 32.74)\tAcc@5  59.20 ( 58.40)\n",
      "Epoch: [1][ 710/1282]\tTime  2.867 ( 1.835)\tData  0.097 ( 0.026)\tLoss 3.0619e+00 (3.1331e+00)\tAcc@1  30.80 ( 32.78)\tAcc@5  59.40 ( 58.46)\n",
      "Epoch: [1][ 720/1282]\tTime  2.892 ( 1.835)\tData  0.002 ( 0.025)\tLoss 2.9105e+00 (3.1307e+00)\tAcc@1  35.60 ( 32.82)\tAcc@5  59.80 ( 58.51)\n",
      "Epoch: [1][ 730/1282]\tTime  2.806 ( 1.834)\tData  0.002 ( 0.025)\tLoss 2.9238e+00 (3.1278e+00)\tAcc@1  37.00 ( 32.87)\tAcc@5  63.20 ( 58.56)\n",
      "Epoch: [1][ 740/1282]\tTime  3.219 ( 1.835)\tData  0.002 ( 0.025)\tLoss 3.0189e+00 (3.1256e+00)\tAcc@1  33.40 ( 32.90)\tAcc@5  61.00 ( 58.59)\n",
      "Epoch: [1][ 750/1282]\tTime  2.850 ( 1.835)\tData  0.003 ( 0.025)\tLoss 2.9499e+00 (3.1229e+00)\tAcc@1  34.00 ( 32.95)\tAcc@5  63.60 ( 58.65)\n",
      "Epoch: [1][ 760/1282]\tTime  2.890 ( 1.835)\tData  0.003 ( 0.024)\tLoss 3.1221e+00 (3.1199e+00)\tAcc@1  33.20 ( 33.00)\tAcc@5  58.00 ( 58.69)\n",
      "Epoch: [1][ 770/1282]\tTime  2.883 ( 1.835)\tData  0.002 ( 0.024)\tLoss 2.8026e+00 (3.1168e+00)\tAcc@1  40.60 ( 33.04)\tAcc@5  65.80 ( 58.76)\n",
      "Epoch: [1][ 780/1282]\tTime  2.878 ( 1.834)\tData  0.003 ( 0.024)\tLoss 2.7227e+00 (3.1138e+00)\tAcc@1  41.40 ( 33.10)\tAcc@5  65.80 ( 58.81)\n",
      "Epoch: [1][ 790/1282]\tTime  2.951 ( 1.834)\tData  0.002 ( 0.023)\tLoss 2.8172e+00 (3.1113e+00)\tAcc@1  38.60 ( 33.13)\tAcc@5  63.20 ( 58.85)\n",
      "Epoch: [1][ 800/1282]\tTime  2.931 ( 1.834)\tData  0.003 ( 0.023)\tLoss 2.8229e+00 (3.1086e+00)\tAcc@1  36.40 ( 33.17)\tAcc@5  63.20 ( 58.90)\n",
      "Epoch: [1][ 810/1282]\tTime  2.964 ( 1.834)\tData  0.003 ( 0.023)\tLoss 2.9308e+00 (3.1059e+00)\tAcc@1  33.20 ( 33.21)\tAcc@5  61.40 ( 58.95)\n",
      "Epoch: [1][ 820/1282]\tTime  2.781 ( 1.834)\tData  0.002 ( 0.023)\tLoss 2.9909e+00 (3.1035e+00)\tAcc@1  33.60 ( 33.25)\tAcc@5  62.80 ( 58.99)\n",
      "Epoch: [1][ 830/1282]\tTime  2.988 ( 1.833)\tData  0.003 ( 0.022)\tLoss 3.0148e+00 (3.1013e+00)\tAcc@1  34.60 ( 33.28)\tAcc@5  62.20 ( 59.04)\n",
      "Epoch: [1][ 840/1282]\tTime  2.809 ( 1.833)\tData  0.002 ( 0.022)\tLoss 2.9431e+00 (3.0991e+00)\tAcc@1  35.60 ( 33.31)\tAcc@5  64.40 ( 59.08)\n",
      "Epoch: [1][ 850/1282]\tTime  2.800 ( 1.833)\tData  0.002 ( 0.022)\tLoss 2.7623e+00 (3.0963e+00)\tAcc@1  38.40 ( 33.36)\tAcc@5  66.60 ( 59.14)\n",
      "Epoch: [1][ 860/1282]\tTime  2.709 ( 1.833)\tData  0.002 ( 0.022)\tLoss 2.9870e+00 (3.0940e+00)\tAcc@1  33.60 ( 33.41)\tAcc@5  62.00 ( 59.18)\n",
      "Epoch: [1][ 870/1282]\tTime  2.547 ( 1.832)\tData  0.002 ( 0.022)\tLoss 2.7994e+00 (3.0915e+00)\tAcc@1  38.20 ( 33.45)\tAcc@5  65.80 ( 59.22)\n",
      "Epoch: [1][ 880/1282]\tTime  2.468 ( 1.833)\tData  0.002 ( 0.021)\tLoss 2.8187e+00 (3.0895e+00)\tAcc@1  38.40 ( 33.47)\tAcc@5  64.00 ( 59.25)\n",
      "Epoch: [1][ 890/1282]\tTime  2.739 ( 1.833)\tData  0.003 ( 0.021)\tLoss 2.9532e+00 (3.0868e+00)\tAcc@1  37.00 ( 33.52)\tAcc@5  60.00 ( 59.29)\n",
      "Epoch: [1][ 900/1282]\tTime  2.730 ( 1.833)\tData  0.002 ( 0.021)\tLoss 2.9097e+00 (3.0848e+00)\tAcc@1  37.80 ( 33.55)\tAcc@5  63.00 ( 59.33)\n",
      "Epoch: [1][ 910/1282]\tTime  2.719 ( 1.832)\tData  0.002 ( 0.021)\tLoss 2.7003e+00 (3.0824e+00)\tAcc@1  41.20 ( 33.60)\tAcc@5  66.60 ( 59.38)\n",
      "Epoch: [1][ 920/1282]\tTime  2.771 ( 1.832)\tData  0.002 ( 0.021)\tLoss 2.8677e+00 (3.0798e+00)\tAcc@1  36.80 ( 33.64)\tAcc@5  62.80 ( 59.43)\n",
      "Epoch: [1][ 930/1282]\tTime  2.945 ( 1.832)\tData  0.003 ( 0.020)\tLoss 2.9419e+00 (3.0776e+00)\tAcc@1  33.40 ( 33.66)\tAcc@5  58.60 ( 59.47)\n",
      "Epoch: [1][ 940/1282]\tTime  2.818 ( 1.831)\tData  0.002 ( 0.020)\tLoss 2.9455e+00 (3.0755e+00)\tAcc@1  37.00 ( 33.70)\tAcc@5  60.80 ( 59.51)\n",
      "Epoch: [1][ 950/1282]\tTime  2.923 ( 1.831)\tData  0.002 ( 0.020)\tLoss 2.9343e+00 (3.0733e+00)\tAcc@1  34.80 ( 33.73)\tAcc@5  61.00 ( 59.55)\n",
      "Epoch: [1][ 960/1282]\tTime  2.881 ( 1.831)\tData  0.002 ( 0.020)\tLoss 2.9116e+00 (3.0707e+00)\tAcc@1  36.20 ( 33.79)\tAcc@5  61.60 ( 59.59)\n",
      "Epoch: [1][ 970/1282]\tTime  2.980 ( 1.832)\tData  0.003 ( 0.020)\tLoss 2.9033e+00 (3.0684e+00)\tAcc@1  34.80 ( 33.82)\tAcc@5  62.60 ( 59.64)\n",
      "Epoch: [1][ 980/1282]\tTime  2.816 ( 1.832)\tData  0.002 ( 0.019)\tLoss 2.8310e+00 (3.0658e+00)\tAcc@1  42.20 ( 33.87)\tAcc@5  63.80 ( 59.69)\n",
      "Epoch: [1][ 990/1282]\tTime  3.164 ( 1.832)\tData  0.003 ( 0.019)\tLoss 2.8058e+00 (3.0633e+00)\tAcc@1  39.20 ( 33.92)\tAcc@5  62.20 ( 59.73)\n",
      "Epoch: [1][1000/1282]\tTime  2.155 ( 1.831)\tData  0.002 ( 0.019)\tLoss 2.9175e+00 (3.0615e+00)\tAcc@1  37.80 ( 33.94)\tAcc@5  61.40 ( 59.76)\n",
      "Epoch: [1][1010/1282]\tTime  2.004 ( 1.831)\tData  0.002 ( 0.019)\tLoss 2.8425e+00 (3.0594e+00)\tAcc@1  35.80 ( 33.98)\tAcc@5  64.00 ( 59.80)\n",
      "Epoch: [1][1020/1282]\tTime  2.687 ( 1.831)\tData  0.002 ( 0.019)\tLoss 2.8574e+00 (3.0576e+00)\tAcc@1  36.20 ( 34.01)\tAcc@5  62.60 ( 59.83)\n",
      "Epoch: [1][1030/1282]\tTime  2.762 ( 1.831)\tData  0.003 ( 0.019)\tLoss 2.8047e+00 (3.0550e+00)\tAcc@1  38.00 ( 34.05)\tAcc@5  65.20 ( 59.88)\n",
      "Epoch: [1][1040/1282]\tTime  3.055 ( 1.832)\tData  0.002 ( 0.018)\tLoss 2.7317e+00 (3.0526e+00)\tAcc@1  37.20 ( 34.09)\tAcc@5  64.20 ( 59.91)\n",
      "Epoch: [1][1050/1282]\tTime  2.501 ( 1.832)\tData  0.002 ( 0.018)\tLoss 2.6975e+00 (3.0500e+00)\tAcc@1  40.20 ( 34.14)\tAcc@5  68.40 ( 59.96)\n",
      "Epoch: [1][1060/1282]\tTime  2.926 ( 1.832)\tData  0.003 ( 0.018)\tLoss 2.7382e+00 (3.0474e+00)\tAcc@1  40.20 ( 34.19)\tAcc@5  65.60 ( 60.02)\n",
      "Epoch: [1][1070/1282]\tTime  3.065 ( 1.833)\tData  0.002 ( 0.018)\tLoss 2.7635e+00 (3.0455e+00)\tAcc@1  37.80 ( 34.21)\tAcc@5  63.00 ( 60.05)\n",
      "Epoch: [1][1080/1282]\tTime  2.901 ( 1.832)\tData  0.002 ( 0.018)\tLoss 2.6864e+00 (3.0433e+00)\tAcc@1  39.60 ( 34.25)\tAcc@5  66.60 ( 60.10)\n",
      "Epoch: [1][1090/1282]\tTime  2.378 ( 1.832)\tData  0.002 ( 0.018)\tLoss 2.7343e+00 (3.0410e+00)\tAcc@1  40.20 ( 34.29)\tAcc@5  66.00 ( 60.14)\n",
      "Epoch: [1][1100/1282]\tTime  2.281 ( 1.832)\tData  0.002 ( 0.018)\tLoss 2.8129e+00 (3.0387e+00)\tAcc@1  36.00 ( 34.33)\tAcc@5  66.00 ( 60.19)\n",
      "Epoch: [1][1110/1282]\tTime  2.666 ( 1.832)\tData  1.943 ( 0.020)\tLoss 2.7891e+00 (3.0371e+00)\tAcc@1  36.80 ( 34.35)\tAcc@5  64.00 ( 60.21)\n",
      "Epoch: [1][1120/1282]\tTime  0.822 ( 1.833)\tData  0.112 ( 0.031)\tLoss 2.8441e+00 (3.0351e+00)\tAcc@1  36.60 ( 34.38)\tAcc@5  60.80 ( 60.25)\n",
      "Epoch: [1][1130/1282]\tTime  0.818 ( 1.832)\tData  0.002 ( 0.039)\tLoss 2.8652e+00 (3.0333e+00)\tAcc@1  37.00 ( 34.42)\tAcc@5  63.40 ( 60.28)\n",
      "Epoch: [1][1140/1282]\tTime  0.808 ( 1.835)\tData  0.112 ( 0.052)\tLoss 2.6029e+00 (3.0313e+00)\tAcc@1  44.00 ( 34.45)\tAcc@5  67.40 ( 60.32)\n",
      "Epoch: [1][1150/1282]\tTime  0.716 ( 1.837)\tData  0.002 ( 0.063)\tLoss 2.8147e+00 (3.0290e+00)\tAcc@1  38.20 ( 34.49)\tAcc@5  61.40 ( 60.36)\n",
      "Epoch: [1][1160/1282]\tTime  0.809 ( 1.836)\tData  0.002 ( 0.071)\tLoss 2.9710e+00 (3.0271e+00)\tAcc@1  35.00 ( 34.51)\tAcc@5  63.00 ( 60.39)\n",
      "Epoch: [1][1170/1282]\tTime  0.825 ( 1.835)\tData  0.002 ( 0.079)\tLoss 2.9192e+00 (3.0255e+00)\tAcc@1  40.20 ( 34.55)\tAcc@5  63.80 ( 60.41)\n",
      "Epoch: [1][1180/1282]\tTime  1.560 ( 1.835)\tData  0.002 ( 0.085)\tLoss 2.7415e+00 (3.0232e+00)\tAcc@1  38.80 ( 34.59)\tAcc@5  65.60 ( 60.46)\n",
      "Epoch: [1][1190/1282]\tTime  1.884 ( 1.834)\tData  0.002 ( 0.088)\tLoss 2.8734e+00 (3.0211e+00)\tAcc@1  37.80 ( 34.63)\tAcc@5  64.40 ( 60.50)\n",
      "Epoch: [1][1200/1282]\tTime  1.424 ( 1.834)\tData  0.002 ( 0.088)\tLoss 2.7365e+00 (3.0186e+00)\tAcc@1  41.00 ( 34.67)\tAcc@5  65.80 ( 60.54)\n",
      "Epoch: [1][1210/1282]\tTime  1.237 ( 1.833)\tData  0.002 ( 0.088)\tLoss 2.9356e+00 (3.0160e+00)\tAcc@1  34.80 ( 34.71)\tAcc@5  63.20 ( 60.58)\n",
      "Epoch: [1][1220/1282]\tTime  1.182 ( 1.833)\tData  0.002 ( 0.087)\tLoss 2.8042e+00 (3.0140e+00)\tAcc@1  39.60 ( 34.74)\tAcc@5  63.80 ( 60.62)\n",
      "Epoch: [1][1230/1282]\tTime  1.600 ( 1.833)\tData  0.003 ( 0.086)\tLoss 2.7639e+00 (3.0117e+00)\tAcc@1  38.60 ( 34.78)\tAcc@5  67.40 ( 60.67)\n",
      "Epoch: [1][1240/1282]\tTime  1.102 ( 1.832)\tData  0.002 ( 0.086)\tLoss 2.7314e+00 (3.0097e+00)\tAcc@1  40.00 ( 34.81)\tAcc@5  65.20 ( 60.70)\n",
      "Epoch: [1][1250/1282]\tTime  0.813 ( 1.832)\tData  0.002 ( 0.085)\tLoss 2.6264e+00 (3.0074e+00)\tAcc@1  41.40 ( 34.84)\tAcc@5  66.40 ( 60.74)\n",
      "Epoch: [1][1260/1282]\tTime  1.034 ( 1.832)\tData  0.002 ( 0.084)\tLoss 2.8349e+00 (3.0054e+00)\tAcc@1  37.20 ( 34.88)\tAcc@5  63.20 ( 60.78)\n",
      "Epoch: [1][1270/1282]\tTime  0.969 ( 1.832)\tData  0.002 ( 0.084)\tLoss 2.7235e+00 (3.0035e+00)\tAcc@1  42.40 ( 34.92)\tAcc@5  65.40 ( 60.82)\n",
      "Epoch: [1][1280/1282]\tTime  1.429 ( 1.832)\tData  0.002 ( 0.083)\tLoss 2.6552e+00 (3.0010e+00)\tAcc@1  41.60 ( 34.97)\tAcc@5  65.40 ( 60.86)\n",
      "Test: [  0/100]\tTime  4.711 ( 4.711)\tLoss 2.3686e+00 (2.3686e+00)\tAcc@1  45.80 ( 45.80)\tAcc@5  73.80 ( 73.80)\n",
      "Test: [ 10/100]\tTime  3.170 ( 2.083)\tLoss 2.6279e+00 (2.9169e+00)\tAcc@1  44.00 ( 37.82)\tAcc@5  67.40 ( 62.38)\n",
      "Test: [ 20/100]\tTime  3.374 ( 1.966)\tLoss 2.9459e+00 (2.9010e+00)\tAcc@1  28.40 ( 35.47)\tAcc@5  63.00 ( 62.37)\n",
      "Test: [ 30/100]\tTime  3.198 ( 1.935)\tLoss 2.9783e+00 (2.8672e+00)\tAcc@1  34.80 ( 34.74)\tAcc@5  60.80 ( 63.29)\n",
      "Test: [ 40/100]\tTime  2.846 ( 2.081)\tLoss 2.7717e+00 (2.8853e+00)\tAcc@1  38.00 ( 35.27)\tAcc@5  64.80 ( 62.98)\n",
      "Test: [ 50/100]\tTime  3.221 ( 2.033)\tLoss 4.1873e+00 (3.0392e+00)\tAcc@1  19.00 ( 33.36)\tAcc@5  40.40 ( 60.43)\n",
      "Test: [ 60/100]\tTime  2.942 ( 2.004)\tLoss 3.5203e+00 (3.0906e+00)\tAcc@1  30.40 ( 33.00)\tAcc@5  52.00 ( 59.60)\n",
      "Test: [ 70/100]\tTime  3.153 ( 1.970)\tLoss 3.7629e+00 (3.1602e+00)\tAcc@1  22.40 ( 32.09)\tAcc@5  47.80 ( 58.43)\n",
      "Test: [ 80/100]\tTime  3.233 ( 1.943)\tLoss 3.3902e+00 (3.2124e+00)\tAcc@1  30.00 ( 31.64)\tAcc@5  53.40 ( 57.55)\n",
      "Test: [ 90/100]\tTime  3.093 ( 1.919)\tLoss 3.5375e+00 (3.2642e+00)\tAcc@1  32.40 ( 30.88)\tAcc@5  53.20 ( 56.63)\n",
      " * Acc@1 31.500 Acc@5 57.382\n",
      "lr: 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, 2):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()[0]))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12f3fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dcf4bb99f4bea973\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dcf4bb99f4bea973\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606d20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
