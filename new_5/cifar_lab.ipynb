{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d329e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f01436",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5eafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a78e77",
   "metadata": {},
   "source": [
    "### Set the architecture to resnet 18 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300adac1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "ARCH = 'resnet18'# set the architecture to RESNET 18\n",
    "# please look up how to do that\n",
    "########################\n",
    "EPOCHS = 200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=128\n",
    "VAL_BATCH=128\n",
    "WORKERS=2\n",
    "# TRAINDIR=\"/workspace/data/imagenet2012/train\"\n",
    "# VALDIR=\"/workspace/data/imagenet2012/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINDIR=\"/CINIC/train\"\n",
    "# VALDIR=\"/CINIC/valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57b86a",
   "metadata": {},
   "source": [
    "### Check if cuda is available here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available in this cell\n",
    "# if it is not available, you should not go forward!\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'Device detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761ee6a",
   "metadata": {},
   "source": [
    "### Assign your GPU below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce66ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your GPU in this cell\n",
    "#GPU = None\n",
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b660e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable algorithm optimization\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7288e8",
   "metadata": {},
   "source": [
    "### Fill in the heart of the train section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    ######################\n",
    "    # switch model to train mode here\n",
    "    model.train()\n",
    "    ################\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        #####################\n",
    "        # send the images to cuda device\n",
    "        # send the target to cuda device\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "\n",
    "\n",
    "        # compute loss \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        \n",
    "        #### zero out gradients in the optimier\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## backprop!\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights!\n",
    "        optimier.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c806b",
   "metadata": {},
   "source": [
    "#### Fill in the validate section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfebd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    # model ???\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            \n",
    "            ### send the images and target to cuda\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss  = criterion(utput, target)\n",
    "\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc9d5f",
   "metadata": {},
   "source": [
    "### Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    # save the model state!\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce54861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c114b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we are adjusting the LR manually use this\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c91f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "# IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397d30d",
   "metadata": {},
   "source": [
    "### Initialize the model using the architecture you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the model\n",
    "# model = ... \n",
    "\n",
    "NUM_CLASSES = 10\n",
    "model = models.__dict__[ARCH]()\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2604ec7",
   "metadata": {},
   "source": [
    "### Send the model to the cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b592b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the model to the cuda device..\n",
    "\n",
    "model.cuda(GPU) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6226d",
   "metadata": {},
   "source": [
    "### Instantiate the loss to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63c9ff",
   "metadata": {},
   "source": [
    "### Instantiate the optimizer to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8811817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGD .. use the momentum and weight decay vars\n",
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                            momentum=MOMENTUM,\n",
    "                            weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb2f32",
   "metadata": {},
   "source": [
    "#### Create the learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f131ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CosineAnnealingLR\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnneaLingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean_RGB, cifar_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7c365",
   "metadata": {},
   "source": [
    "### Create the train dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2568366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torchvision.datasets.CIFAR10\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean_RGB, cifar_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd3e250",
   "metadata": {},
   "source": [
    "### Create the val dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ecf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torchvision.datasets.CIFAR10\n",
    "val_dataset = torchvisision.datasets.CIFAR(\n",
    "    root='./data', train=False, download=True, transform=transform_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6c58e",
   "metadata": {},
   "source": [
    "### Create the train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=TRAIN_BATCH,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=WORKERS,\n",
    "                                           pin_memory=True,\n",
    "                                           sampler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1e1ef",
   "metadata": {},
   "source": [
    "### Create the c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c48b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in..\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=VAL_BATCH,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=WORKERS,\n",
    "                                         pin_memory=True,\n",
    "                                         sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b1fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339748d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf1c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
